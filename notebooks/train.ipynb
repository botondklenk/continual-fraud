{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preparation import DataPreparation\n",
    "from models.rfc import RFCModel\n",
    "from features.feature_scaler import feature_scaling\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPreparation('../data/fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   merchant    1296675 non-null  int64  \n",
      " 1   category    1296675 non-null  int64  \n",
      " 2   amt         1296675 non-null  float64\n",
      " 3   gender      1296675 non-null  int64  \n",
      " 4   city        1296675 non-null  int64  \n",
      " 5   state       1296675 non-null  int64  \n",
      " 6   lat         1296675 non-null  float64\n",
      " 7   long        1296675 non-null  float64\n",
      " 8   city_pop    1296675 non-null  int64  \n",
      " 9   job         1296675 non-null  int64  \n",
      " 10  dob         1296675 non-null  int64  \n",
      " 11  unix_time   1296675 non-null  int64  \n",
      " 12  merch_lat   1296675 non-null  float64\n",
      " 13  merch_long  1296675 non-null  float64\n",
      " 14  is_fraud    1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(10)\n",
      "memory usage: 148.4 MB\n",
      "None\n",
      "(1296675, 15)\n"
     ]
    }
   ],
   "source": [
    "dp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>514</td>\n",
       "      <td>8</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>27</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>370</td>\n",
       "      <td>779</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241</td>\n",
       "      <td>4</td>\n",
       "      <td>107.23</td>\n",
       "      <td>0</td>\n",
       "      <td>612</td>\n",
       "      <td>47</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>428</td>\n",
       "      <td>607</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>220.11</td>\n",
       "      <td>1</td>\n",
       "      <td>468</td>\n",
       "      <td>13</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>307</td>\n",
       "      <td>302</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>2</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>26</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>328</td>\n",
       "      <td>397</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297</td>\n",
       "      <td>9</td>\n",
       "      <td>41.96</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>45</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>116</td>\n",
       "      <td>734</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merchant  category     amt  gender  city  state      lat      long  \\\n",
       "0       514         8    4.97       0   526     27  36.0788  -81.1781   \n",
       "1       241         4  107.23       0   612     47  48.8878 -118.2105   \n",
       "2       390         0  220.11       1   468     13  42.1808 -112.2620   \n",
       "3       360         2   45.00       1    84     26  46.2306 -112.1138   \n",
       "4       297         9   41.96       1   216     45  38.4207  -79.4629   \n",
       "\n",
       "   city_pop  job  dob   unix_time  merch_lat  merch_long  is_fraud  \n",
       "0      3495  370  779  1325376018  36.011293  -82.048315         0  \n",
       "1       149  428  607  1325376044  49.159047 -118.186462         0  \n",
       "2      4154  307  302  1325376051  43.150704 -112.154481         0  \n",
       "3      1939  328  397  1325376076  47.034331 -112.561071         0  \n",
       "4        99  116  734  1325376186  38.674999  -78.632459         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = dp.get_data()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop('is_fraud', axis=1), train_df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RFCModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   merchant    555719 non-null  int64  \n",
      " 1   category    555719 non-null  int64  \n",
      " 2   amt         555719 non-null  float64\n",
      " 3   gender      555719 non-null  int64  \n",
      " 4   city        555719 non-null  int64  \n",
      " 5   state       555719 non-null  int64  \n",
      " 6   lat         555719 non-null  float64\n",
      " 7   long        555719 non-null  float64\n",
      " 8   city_pop    555719 non-null  int64  \n",
      " 9   job         555719 non-null  int64  \n",
      " 10  dob         555719 non-null  int64  \n",
      " 11  unix_time   555719 non-null  int64  \n",
      " 12  merch_lat   555719 non-null  float64\n",
      " 13  merch_long  555719 non-null  float64\n",
      " 14  is_fraud    555719 non-null  int64  \n",
      "dtypes: float64(5), int64(10)\n",
      "memory usage: 63.6 MB\n",
      "None\n",
      "(555719, 15)\n"
     ]
    }
   ],
   "source": [
    "dp_test = DataPreparation('../data/fraudTest.csv')\n",
    "dp_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dp_test.get_data()\n",
    "X_test, y_test = test_df.drop('is_fraud', axis=1), test_df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benya/edu/continual-fraud/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "metrics = rfc.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_score = pd.DataFrame(data = metrics, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "rf_score.insert(0, 'Random Forest with', 'No Under/Oversampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Under/Oversampling</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Random Forest with  Recall  Precision  F1 Score  Accuracy\n",
       "0  No Under/Oversampling     0.0        0.0       0.0   0.99614"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merchant': 0.0006263105874443632,\n",
       " 'category': 0.07846230897998699,\n",
       " 'amt': 0.7560244282587812,\n",
       " 'gender': 0.006533783792897625,\n",
       " 'city': 0.0009154646471433975,\n",
       " 'state': 0.00233744394993332,\n",
       " 'lat': 0.08215638041611112,\n",
       " 'long': 1.235960350524123e-05,\n",
       " 'city_pop': 0.007655564727005781,\n",
       " 'job': 0.0032283512584462093,\n",
       " 'dob': 0.01610109797584191,\n",
       " 'unix_time': 0.004600646624103639,\n",
       " 'merch_lat': 0.03232344392631547,\n",
       " 'merch_long': 0.00902241525248374}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.get_feature_importance(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/edu/continual-fraud/notebooks/../src/models/rfc.py:24\u001b[0m, in \u001b[0;36mRFCModel.confusion_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/edu/continual-fraud/notebooks/../src/evaluate/evaluate.py:36\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(y_true, y_pred):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Compute the confusion matrix.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        array: Confusion matrix.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/edu/continual-fraud/notebooks/../src/evaluate/evaluate.py:36\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(y_true, y_pred):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Compute the confusion matrix.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        array: Confusion matrix.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: confusion_matrix at line 36 (2968 times)]\u001b[0m\n",
      "File \u001b[0;32m~/edu/continual-fraud/notebooks/../src/evaluate/evaluate.py:36\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(y_true, y_pred):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Compute the confusion matrix.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        array: Confusion matrix.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "#rfc.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.save_model('../models/rfc1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.load_model('../models/rfc1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_scaling(X_train, ['amt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Class weights</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Random Forest with  Recall  Precision  F1 Score  Accuracy\n",
       "0      Class weights     0.0        0.0       0.0  0.996138"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = rfc.evaluate(X_test, y_test)\n",
    "feature_scaling_rf_score = pd.DataFrame(data = metrics, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "feature_scaling_rf_score.insert(0, 'Random Forest with', 'Feauture Scaling')\n",
    "feature_scaling_rf_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [4, 6, 10, 12],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "grid_rf = GridSearchCV(rfc.get_model(), param_grid=params, cv=kf, \n",
    "                          scoring='recall').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 12, 'n_estimators': 20, 'random_state': 13}\n",
      "Best score: 0.6223851653269769\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid_rf.best_params_)\n",
    "print('Best score:', grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RFCModel' object has no attribute 'replace_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_model\u001b[49m(grid_rf\u001b[38;5;241m.\u001b[39mbest_estimator_)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RFCModel' object has no attribute 'replace_model'"
     ]
    }
   ],
   "source": [
    "#rfc.replace_model(grid_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc = grid_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12367"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate.evaluate import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [(evaluation['recall'], evaluation['precision'], evaluation['f1_score'], evaluation['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feauture Scaling and GridSearchCV</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.973951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Random Forest with    Recall  Precision  F1 Score  Accuracy\n",
       "0  Feauture Scaling and GridSearchCV  0.008392   0.001455  0.002481  0.973951"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics = rfc.evaluate(X_test, y_test)\n",
    "feature_scaling_gridsearch_rf_score = pd.DataFrame(data = metrics, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
    "feature_scaling_gridsearch_rf_score.insert(0, 'Random Forest with', 'Feauture Scaling and GridSearchCV')\n",
    "feature_scaling_gridsearch_rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[541225,  12349],\n",
       "       [  2127,     18]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feauture Scaling and GridSearchCV</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.973951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Under/Oversampling</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Class weights</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Random Forest with    Recall  Precision  F1 Score  Accuracy\n",
       "2  Feauture Scaling and GridSearchCV  0.008392   0.001455  0.002481  0.973951\n",
       "0              No Under/Oversampling  0.000000   0.000000  0.000000  0.996140\n",
       "1                      Class weights  0.000000   0.000000  0.000000  0.996138"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.concat([rf_score, feature_scaling_rf_score, feature_scaling_gridsearch_rf_score], ignore_index=True, sort=False)\n",
    "predictions.sort_values(by=['Recall'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
