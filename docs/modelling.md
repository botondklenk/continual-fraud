The most common metrics to use for imbalanced datasets are:

- F1 score
- Precision
- Recall
- AUC score (AUC ROC)
- Average precision score (AP)
- G-Mean

It is good practice to track multiple metrics when developing a machine learning model as each highlights different aspects of model performance.

https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/

